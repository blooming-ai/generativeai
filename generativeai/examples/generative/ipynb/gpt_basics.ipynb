{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaIrNRZ6FNMnjfEDscOum4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blooming-ai/generativeai/blob/main/generativeai/examples/generative/ipynb/gpt_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT code\n",
        "https://github.com/karpathy/minGPT"
      ],
      "metadata": {
        "id": "uWPGKPjM-93N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get data file\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xENHd64F_DLN",
        "outputId": "541e91a7-d8ea-4bcf-d203-22c1266d6e84"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-10 12:32:28--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-08-10 12:32:28 (18.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embedding"
      ],
      "metadata": {
        "id": "j5poGeV3_EPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv input.txt sample_data/\n",
        "file_path = \"sample_data/input.txt\""
      ],
      "metadata": {
        "id": "YNfY72IKF9V6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pdb\n",
        "import string\n",
        "#Inspired from https://www.geeksforgeeks.org/byte-pair-encoding-bpe-in-nlp/\n",
        "# But rewritten for better understanding and working on files\n",
        "\n",
        "#Byte pair encoding\n",
        "def construct_word_vocab(word_vocab:dict, file_path:str)->dict:\n",
        "    '''\n",
        "    Read file and update word_vocab dict. word_vocab has format word_vocab[('w','o','r','d')]->freq\n",
        "    '''\n",
        "    with open(file_path) as fp:\n",
        "        while True:\n",
        "            line = fp.readline()\n",
        "            if not line: break\n",
        "            else:\n",
        "                lst = line.split()\n",
        "                for item in lst:\n",
        "                    item.strip()\n",
        "                    item = \"\".join(ch for ch in item if ch.isalnum()) # keep only alpha-numeric characters\n",
        "                    lst_item = list(item.lower())\n",
        "                    lst_item.append(\"\\w\") # add end of word\n",
        "                    lst_item = tuple(lst_item) # tuple to make a hashable dict key\n",
        "                    if len(lst_item) == 0: continue #ignore empty key\n",
        "                    if lst_item not in word_vocab: word_vocab[lst_item] = 1\n",
        "                    else:                     word_vocab[lst_item] += 1\n",
        "\n",
        "    return word_vocab\n",
        "\n",
        "def get_byte_pair_hist(word_vocab:dict)->dict:\n",
        "    '''\n",
        "    Read word_vocab[('w','o','r','d\\w')]->freq and construct byte pair histogram\n",
        "    returns pair[('w','o')]->freq\n",
        "    '''\n",
        "    pair = {}\n",
        "    for word, freq in word_vocab.items():\n",
        "        for i in range(len(word)-1):\n",
        "            key = (word[i],word[i+1])\n",
        "            if key not in pair: pair[key] = freq\n",
        "            else:               pair[key] += freq\n",
        "\n",
        "    return pair\n",
        "\n",
        "def merge_pair(replace_pair:tuple, word_vocab_in:dict)->dict:\n",
        "    '''\n",
        "    replace pair in the key of the word_vocab. E.g. pair=('w','o') then update\n",
        "    word_vocab_in[('w','o','r','d')]->freq to\n",
        "    word_vocab_in[('wo','r','d')]->freq\n",
        "    '''\n",
        "    word_vocab_out = {}\n",
        "    for word, freq in word_vocab_in.items():\n",
        "        word_new = list()\n",
        "        is_last_char_used = False\n",
        "        i=0\n",
        "        while i < len(word)-1:\n",
        "            if (word[i],word[i+1]) == replace_pair:\n",
        "                word_new.append(word[i]+word[i+1])\n",
        "                if i == len(word)-2: is_last_char_used = True\n",
        "                i += 1 # skip the next merged character\n",
        "            else:\n",
        "                word_new.append(word[i])\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        if not is_last_char_used : word_new.append(word[len(word)-1])\n",
        "        word_vocab_out[tuple(word_new)] = freq\n",
        "\n",
        "    return word_vocab_out\n",
        "\n",
        "def byte_pair_encoding(word_vocab:dict, n:int=0)->dict:\n",
        "    '''\n",
        "    Given word_vocab_in[('w','o','r','d')]->freq merges pairs with highest frequency 'n' times.\n",
        "    If n==0, runs till all pairs are merged.\n",
        "    E.g. if ('w','o') has highest freq. then word_vocab_in[('wo','r','d')]->freq.\n",
        "    Also returns the final vocab.\n",
        "    '''\n",
        "    i = 0\n",
        "    vocab = list(string.ascii_lowercase)\n",
        "    vocab.extend(list(string.digits))\n",
        "    # print(vocab)\n",
        "    while True:\n",
        "        pairs = get_byte_pair_hist(word_vocab)\n",
        "        best = max(pairs, key=pairs.get)\n",
        "        vocab.append(best[0]+best[1])\n",
        "        if pairs[best] == 1: break # do not replace if pair occurs only once.\n",
        "        word_vocab = merge_pair(best, word_vocab)\n",
        "        if(i>= n and n>0): break # break if i exceeds n\n",
        "        i += 1\n",
        "\n",
        "    return word_vocab, vocab\n"
      ],
      "metadata": {
        "id": "0Ug-MKi2_G9J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing:\n",
        "# word_vocab = {}\n",
        "# word_vocab = construct_word_vocab(word_vocab, file_path)\n",
        "# print(\"is empyt string a key in word_vocab:\",() in word_vocab)\n",
        "# pairs = get_byte_pair_hist(word_vocab)\n",
        "# best = max(pairs, key=pairs.get)\n",
        "# word_vocab_out = merge_pair(('f','i'), word_vocab)\n",
        "\n",
        "# print(word_vocab)\n",
        "# print(pairs)\n",
        "# print(best)\n",
        "# print(word_vocab_out)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KVwl4FhpowqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vocab = construct_word_vocab(dict(), file_path)\n",
        "bpe_word_vocab, vocab = byte_pair_encoding(word_vocab, 200)\n",
        "\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "5rwLM-5kr6kx",
        "outputId": "8d1e5460-1215-4c95-ea06-3e2febb4b896",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'e\\\\w', 'th', 's\\\\w', 't\\\\w', 'd\\\\w', 'r\\\\w', 'y\\\\w', 'ou', 'an', 'in', 'o\\\\w', 'en', 'l\\\\w', 'on', 'ar', 'er', 'and\\\\w', 'the\\\\w', 'or', 'ha', 'er\\\\w', 'is\\\\w', 'f\\\\w', 'you', 'll\\\\w', 'i\\\\w', 'to\\\\w', 'ea', 'ing', 'no', 'wi', 'es', 'th\\\\w', 'om', 'a\\\\w', 'of\\\\w', 'ch', 'es\\\\w', 'ing\\\\w', 'in\\\\w', 've\\\\w', 'st', 'at\\\\w', 'my\\\\w', 'you\\\\w', 'ed\\\\w', 'en\\\\w', 'or\\\\w', 'li', 'm\\\\w', 'wh', 'ow', 'st\\\\w', 'on\\\\w', 'me\\\\w', 'that\\\\w', 'ti', 'ri', 'k\\\\w', 'ce\\\\w', 'el', 'ay\\\\w', 'the', 'sh', 'not\\\\w', 'an\\\\w', 'it\\\\w', 'as\\\\w', 'bu', 're', 'ke\\\\w', 'gh', 'et\\\\w', 'ld\\\\w', 'se\\\\w', 'oo', 'for\\\\w', 'thou', 'with\\\\w', 'la', 'si', 'ere\\\\w', 'us\\\\w', 'ma', 'be\\\\w', 'ra', 'di', 'your\\\\w', 'ro', 'ch\\\\w', 'hi', 'le\\\\w', 'ur', 'be', 'his\\\\w', 'com', 'but\\\\w', 'this\\\\w', 'he\\\\w', 'un', 'w\\\\w', 'have\\\\w', 'fa', 'thou\\\\w', 'ds\\\\w', 'for', 'ca', 'n\\\\w', 'ther\\\\w', 'ol', 'ow\\\\w', 'wha', 'our\\\\w', 'him\\\\w', 'so\\\\w', 'ts\\\\w', 'se', 'we', 'ta', 'ru', 'mi', 'sha', 'what\\\\w', 'thy\\\\w', 'ly\\\\w', 'sp', 'le', 'rom', 'fi', 'ard\\\\w', 'now\\\\w', 'p\\\\w', 'will\\\\w', 'lo', 'king\\\\w', 'ould\\\\w', 'one\\\\w', 'ter\\\\w', 'sa', 'by\\\\w', 'ess\\\\w', 'rea', 'are\\\\w', 'ood\\\\w', 'ght\\\\w', 'su', 'lor', 'ear\\\\w', 'all\\\\w', 'ne', 'con', 'no\\\\w', 'ci', 'ear', 'est\\\\w', 'we\\\\w', 'at', 'ty\\\\w', 'shall\\\\w', 'ers\\\\w', 'ir\\\\w', 'qu', 'whi', 'her\\\\w', 'de', 'wor', 'ent\\\\w', 'if\\\\w', 'thee\\\\w', 'do\\\\w', 'du', 'al', 'vi', 'come\\\\w', 'mor', 'ck\\\\w', 'mu', 'ge\\\\w', 'ry\\\\w', 'pr', 'mo', 'lord\\\\w', 'ence\\\\w', 'po', 'pa', 'well\\\\w', 'good\\\\w', 'ver', 'oun', 'pe', 'ill\\\\w', 'mar', 'sel', 'bo', 'from', 'from\\\\w', 'man\\\\w', 'own\\\\w', 'ga', 'pro', 'am\\\\w']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "tN8q7CY3_Hp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sinusoidal position encoding"
      ],
      "metadata": {
        "id": "RPuQMr6H_KAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "0wE7fcxq_K0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def def_value():\n",
        "  '''\n",
        "  Function to return a default values for a key that is not present in\n",
        "  defaultdict\n",
        "  '''\n",
        "  return 0\n",
        "a = 'aa'\n",
        "di = defaultdict()\n",
        "di[a] += 1\n",
        "print(di)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "wC57DsNd_R0c",
        "outputId": "8265b191-0b6c-4a4d-c77d-3410abce6fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-415c96786a08>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'aa'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'aa'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Setup"
      ],
      "metadata": {
        "id": "BhqAQ_-s_eKW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulrU1aFp_h6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "ZA2A2VJi_iea"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R4HP3YhA_mgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "0YvNcwEO_nLT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkDncGaJ_o3O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}